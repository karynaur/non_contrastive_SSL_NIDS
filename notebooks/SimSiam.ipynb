{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from data.dataset import MultiViewIntrusionData, MultiViewIntrusionDataTransformer\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from data.augmentation import MultiViewDataInjector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set\n",
    "test_ratio = 0.5\n",
    "contamination_rate = 0.0\n",
    "\n",
    "# general\n",
    "ckpt_root = '../tmp'\n",
    "ckpt_file = None # if checkpoint\n",
    "\n",
    "benign_label = 0\n",
    "anomaly_label = 1\n",
    "batch_size = 512\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-4\n",
    "epochs = 1\n",
    "device = 'cuda'\n",
    "\n",
    "# ssl params\n",
    "encoder_class = 'CNN'\n",
    "encoder_args = {}\n",
    "mlp_params = {\n",
    "    'embedding_dim': 256,\n",
    "    'output_dim': 256,\n",
    "    'n_layers': 2,\n",
    "    'batch_norm': True,\n",
    "    'dropout': False,\n",
    "}\n",
    "\n",
    "# augmentation params\n",
    "transformations = [[{'ShuffleSwapNoise': {'p': 0.4}}], [{'ShuffleSwapNoise': {'p': 0.4}}]]\n",
    "mixup_alpha = None\n",
    "n_subsets = 2\n",
    "overlap = 1.0\n",
    "subsets = n_subsets != 2 or overlap != 1.0\n",
    "if subsets:\n",
    "    transformations = [None]*n_subsets # subsets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define augmentations\n",
    "train_transform = MultiViewDataInjector(transformations, n_subsets, overlap, training=True)\n",
    "test_transform = None if subsets is False else MultiViewDataInjector([None] * n_subsets, n_subsets, overlap, training=False)\n",
    "\n",
    "# load data set\n",
    "path_to_dataset = '../data/processed/unswnb15.csv'\n",
    "if encoder_class == 'FTTransformerEncoder':\n",
    "    dataset = MultiViewIntrusionDataTransformer(path_to_dataset, train_transform, test_transform, shuffle_features=subsets)\n",
    "    encoder_args = {\n",
    "        'categorical_col_indices': dataset.categorical_cols_idx,\n",
    "        'categories_unique_values': dataset.unique_cats,\n",
    "        'numeric_col_indices': dataset.numeric_cols_idx\n",
    "    }\n",
    "    if n_subsets > 2 or overlap < 1.0:\n",
    "        # workaround\n",
    "        encoder_args['numeric_col_indices'] = range(0, (train_transform.n_overlap + train_transform.n_features_subset))\n",
    "else:\n",
    "    dataset = MultiViewIntrusionData(path_to_dataset, train_transform, test_transform, shuffle_features=subsets)\n",
    "\n",
    "train_set, test_set = dataset.split_train_test(test_ratio=test_ratio, contamination_rate=contamination_rate, pos_label=anomaly_label)\n",
    "train_ldr = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_ldr = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('columns: ', dataset.columns)\n",
    "\n",
    "print('train set: ')\n",
    "print('samples: ', len(train_set))\n",
    "print('normal samples: ', len(np.where(train_set.labels == benign_label)[0]))\n",
    "print('malicious samples: ', len(np.where(train_set.labels == anomaly_label)[0]))\n",
    "print(\"\\n\")\n",
    "print('test set: ')\n",
    "print('samples: ', len(test_set))\n",
    "print('normal samples: ', len(np.where(test_set.labels == benign_label)[0]))\n",
    "print('malicious samples: ', len(np.where(test_set.labels == anomaly_label)[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimSiam Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ssl.simsiam import SimSiam\n",
    "from trainer.ssl.simsiam import SimSiam_Trainer\n",
    "\n",
    "if encoder_class == 'CNN' or encoder_class == 'MLP_Encoder':\n",
    "    encoder_args['num_features'] = dataset.in_features\n",
    "\n",
    "model = SimSiam(\n",
    "    device=device,\n",
    "    in_features=dataset.in_features,\n",
    "    n_instances=dataset.n_instances,\n",
    "    encoder_class=encoder_class,\n",
    "    mixup_alpha=mixup_alpha,\n",
    "    mlp_params=mlp_params,\n",
    "    **encoder_args\n",
    ")\n",
    "\n",
    "trainer = SimSiam_Trainer(\n",
    "    model=model,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    n_epochs=epochs,\n",
    "    device=device,\n",
    "    anomaly_label=anomaly_label,\n",
    "    test_ldr=None,\n",
    "    ckpt_root=ckpt_root\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If loading a checkpoint from file\n",
    "if ckpt_file:\n",
    "    from trainer.ssl.simsiam import SimSiam_Trainer\n",
    "    trainer, model = SimSiam_Trainer.load_from_file(ckpt_file, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "trainer.train(train_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ssl_evaluation.kmeans import KMeans_Eval\n",
    "if subsets:\n",
    "    train_set.transform.transformations = [None] * n_subsets\n",
    "else:\n",
    "    train_set.transform = None\n",
    "\n",
    "kmeans = KMeans_Eval(\n",
    "    encoder = model.get_encoder(),\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "kmeans.fit(train_ldr)\n",
    "kmeans.validate(test_ldr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3dd0f9ff1e75967e5b18de7cfeadb54785350b1effac9294121d6095df17f9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
